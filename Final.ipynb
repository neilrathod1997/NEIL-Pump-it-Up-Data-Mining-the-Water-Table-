{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf492a0",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1b2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import  balanced_accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from joblib import dump, load\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f3c30",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbc66ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "# complete test data\n",
    "test_values = pd.read_csv('test_set_value.csv', parse_dates = ['date_recorded' ],  na_values = [0, '0'])\n",
    "\n",
    "#train test split data\n",
    "x_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "test = test_values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93487115",
   "metadata": {},
   "source": [
    "# Custom Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8024212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# referd from https://github.com/scikit-learn/scikit-learn/issues/12720\n",
    "\n",
    "# this function can lable encode multiple columns at once where sklearns label encoder only encode one column at a time and we can not use it in pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class My_LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit( self , df ,df_y  ):\n",
    "      maps_={}\n",
    "      for col in df:\n",
    "        y = df[col]\n",
    "        uni = np.unique(y)\n",
    "        map_ = {}\n",
    "        for c in uni:\n",
    "            map_[c] = len(map_)\n",
    "        maps_[col] = map_\n",
    "      self.maps_ = maps_\n",
    "      return self\n",
    "\n",
    "\n",
    "    def transform(self , df):\n",
    "      ndf = df.copy()\n",
    "      for col in df:\n",
    "        ny = []\n",
    "        map_= self.maps_[col]\n",
    "        for c in np.array(df[col]):\n",
    "          if c in self.maps_[col]:\n",
    "            ny.append(self.maps_[col][c])\n",
    "          else:\n",
    "            ny.append(-1)\n",
    "        ndf[col] = ny\n",
    "      return ndf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c83778",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fe685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Function_1(X):\n",
    "    \"\"\" THIS FUNCTION TAKES RAW DATA AND DOSE PREPROCESSING AND FEATURE ENGG. AND predict using best model\"\"\"\n",
    "    test = X.copy()\n",
    "    # longitude\n",
    "    means_longitude_subvillage = pd.read_csv('means_longitude_subvillage.csv')\n",
    "    means_longitude_ward = pd.read_csv('means_longitude_ward.csv', )\n",
    "    means_longitude_lga = pd.read_csv('means_longitude_lga.csv', )\n",
    "    means_longitude_region = pd.read_csv('means_longitude_region.csv', )\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df this will make it easier to replace missing values\n",
    "    test = test.merge(means_longitude_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_longitude_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_longitude_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_longitude_region, how='left', on=['region'])\n",
    "\n",
    "    # select the right longitude level based on the availability of information\n",
    "    test['imputed_longitude'] = np.where(test['longitude'].isna(), test['longitude_imputed_subvillage'], test[\n",
    "        'longitude'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_ward'], test[\n",
    "        'imputed_longitude'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_lga'],\n",
    "                                         test['imputed_longitude'])\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_region'],\n",
    "                                         test['imputed_longitude'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(\n",
    "        ['longitude_imputed_subvillage', 'longitude_imputed_ward', 'longitude_imputed_lga', 'longitude_imputed_region',\n",
    "         'longitude'], axis=1)\n",
    "\n",
    "    # Premit\n",
    "    permit_mg_mode = pd.read_csv('permit_mg_mode3.csv')\n",
    "\n",
    "    permit_mg_mode = permit_mg_mode.rename(columns={\"permit\": \"imputed_permit_mg\"})\n",
    "    test = test.merge(permit_mg_mode, how='left', on=['public_meeting', 'management_group'])\n",
    "\n",
    "    test['imputed_permit'] = np.where(test['permit'].isna(), test['imputed_permit_mg'], test[\n",
    "        'permit'])  # if permit is missing, replace it by the mode of public meeting - management group\n",
    "    test['imputed_permit'] = np.where(test['imputed_permit'].isna(), test['permit'].mode(), test[\n",
    "        'imputed_permit'])  # if eitther public meeting or management group is missing, then use the mode of permit (True)\n",
    "\n",
    "    # drop original permit column\n",
    "    test = test.drop(['permit', 'imputed_permit_mg'], axis=1)\n",
    "\n",
    "    #  Public Meeting\n",
    "    # True is  mode of public meeting.\n",
    "    # Over 90% of the pumps have a public meeting. I will therefore impute by the mode.\n",
    "    test['public_meeting'] = test['public_meeting'].fillna(True)\n",
    "\n",
    "    # Scheme management\n",
    "    scheme_mode = pd.read_csv('permit_mg_mode.csv')\n",
    "\n",
    "    # merge scheme_mode to original df and use it to replace missing values\n",
    "    test = test.merge(scheme_mode, how='left', on=['management'])\n",
    "    test['imputed_scheme__management'] = np.where(test['scheme_management'].isna(), test['imputed_scheme_management'],\n",
    "                                                  test['scheme_management'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['scheme_management', 'imputed_scheme_management'], axis=1)\n",
    "\n",
    "    # Installer\n",
    "    test['installer'] = test['installer'].str.lower()\n",
    "\n",
    "    # plot top 10 installers\n",
    "    test['installer'] = np.where(test['installer'] == 'gove', 'gover', test['installer'])\n",
    "    test['installer'] = np.where(test['installer'] == 'community', 'commu', test['installer'])\n",
    "    test['installer'] = np.where(test['installer'] == 'danid', 'danida', test['installer'])\n",
    "\n",
    "    inst150 = pd.read_csv('inst150.csv')\n",
    "    top_installers = np.array(inst150['0'])\n",
    "    # replace funders that are not in top 10 with 'other'\n",
    "    test['installer'] = np.where(test['installer'].isin(top_installers), test['installer'], 'other')\n",
    "\n",
    "    # Funder\n",
    "    # set al entries to lowercase\n",
    "    test['funder'] = test['funder'].str.lower()\n",
    "\n",
    "    fund150 = pd.read_csv('fundt150.csv')\n",
    "    top_funders = np.array(fund150['0'])\n",
    "\n",
    "    # replace funders that are not in top 150 with 'other'\n",
    "    test['funder'] = np.where(test['funder'].isin(top_funders), test['funder'], 'other')\n",
    "\n",
    "    # Construction Year\n",
    "    mean_construction = pd.read_csv('mean_construction.csv')\n",
    "\n",
    "    mean_construction = mean_construction.rename(columns={\"construction_year\": \"imputed_construction_year\"})\n",
    "\n",
    "    # merge this df to the main df and replace missing values\n",
    "    test = test.merge(mean_construction, how='left', on='extraction_type_group')\n",
    "    test['construction_year_imputed'] = np.where(test['construction_year'].isna(), test['imputed_construction_year'],\n",
    "                                                 test['construction_year'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['imputed_construction_year', 'construction_year'], axis=1)\n",
    "\n",
    "    # GPS height\n",
    "    # subvillage\n",
    "    means_altitude_subvillage = pd.read_csv('means_altitude_subvillage.csv', )\n",
    "\n",
    "    # ward level\n",
    "    means_altitude_ward = pd.read_csv('means_altitude_ward.csv')\n",
    "\n",
    "    # lga level\n",
    "    means_altitude_lga = pd.read_csv('means_altitude_lga.csv')\n",
    "\n",
    "    # region level\n",
    "    means_altitude_region = pd.read_csv('means_altitude_region.csv')\n",
    "\n",
    "    # region basin\n",
    "    means_altitude_basin = pd.read_csv('means_altitude_basin.csv')\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df\n",
    "    test = test.merge(means_altitude_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_altitude_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_altitude_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_altitude_region, how='left', on=['region'])\n",
    "    test = test.merge(means_altitude_basin, how='left', on=['basin'])\n",
    "\n",
    "    # create final imputed longitude column\n",
    "    test['imputed_gps_height'] = np.where(test['gps_height'].isna(), test['gps_height_imputed_subvillage'], test[\n",
    "        'gps_height'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_ward'], test[\n",
    "        'imputed_gps_height'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_lga'],\n",
    "                                          test['imputed_gps_height'])\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_region'],\n",
    "                                          test['imputed_gps_height'])\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_basin'],\n",
    "                                          test['imputed_gps_height'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['gps_height_imputed_subvillage', 'gps_height_imputed_ward', 'gps_height_imputed_lga',\n",
    "                      'gps_height_imputed_region', 'gps_height', 'gps_height_imputed_basin'], axis=1)\n",
    "\n",
    "    # Population\n",
    "\n",
    "    # subvillage\n",
    "    means_population_subvillage = pd.read_csv('means_population_subvillage.csv')\n",
    "\n",
    "    # ward level\n",
    "    means_population_ward = pd.read_csv('means_population_ward.csv')\n",
    "\n",
    "    # lga level\n",
    "    means_population_lga = pd.read_csv('means_population_lga.csv')\n",
    "\n",
    "    # region level\n",
    "    means_population_region = pd.read_csv('means_population_region.csv')\n",
    "\n",
    "    # region basin\n",
    "    means_population_basin = pd.read_csv('means_population_basin.csv')\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df\n",
    "    test = test.merge(means_population_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_population_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_population_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_population_region, how='left', on=['region'])\n",
    "    test = test.merge(means_population_basin, how='left', on=['basin'])\n",
    "\n",
    "    # create final imputed longitude column\n",
    "    test['imputed_population'] = np.where(test['population'].isna(), test['population_imputed_subvillage'], test[\n",
    "        'population'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_ward'], test[\n",
    "        'imputed_population'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_lga'],\n",
    "                                          test['imputed_population'])\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_region'],\n",
    "                                          test['imputed_population'])\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_basin'],\n",
    "                                          test['imputed_population'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['population_imputed_subvillage', 'population_imputed_ward', 'population_imputed_lga',\n",
    "                      'population_imputed_region', 'population', 'population_imputed_basin'], axis=1)\n",
    "\n",
    "    # change type to categorical\n",
    "\n",
    "    test['num_private'] = test['num_private'].astype('str')\n",
    "    test['region_code'] = test['region_code'].astype('str')\n",
    "    test['district_code'] = test['district_code'].astype('str')\n",
    "    test['num_private'] = test['num_private'].astype('str')\n",
    "\n",
    "    # replace string to integer\n",
    "    test['public_meeting'] = test['public_meeting'].replace({True: 1, False: 0})\n",
    "    test['imputed_permit'] = test['imputed_permit'].replace({True: 1, False: 0})\n",
    "\n",
    "    # change to integer\n",
    "    test[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']] = test[\n",
    "        ['imputed_gps_height', 'construction_year_imputed', 'imputed_population']].astype('int')\n",
    "\n",
    "    # change type to categorical\n",
    "\n",
    "    # remove decimal\n",
    "    test['district_code'] = test['district_code'].str.split(\".\").str[0]\n",
    "\n",
    "    test = test.rename(columns={\"imputed_permit\": \"permit\", \"imputed_scheme__management\": \"scheme_management\",\n",
    "                                \"imputed_gps_height\": \"gps_height\", 'construction_year_imputed': 'construction_year',\n",
    "                                'imputed_population': 'population', 'imputed_longitude': 'longitude'}, errors=\"raise\")\n",
    "\n",
    "    final_df_test = test.copy()\n",
    "\n",
    "    # create age feature\n",
    "    final_df_test['recorded_year'] = pd.DatetimeIndex(final_df_test['date_recorded']).year\n",
    "    final_df_test['age'] = final_df_test['recorded_year'] - final_df_test['construction_year']\n",
    "    final_df_test = final_df_test.drop('recorded_year', axis=1)\n",
    "\n",
    "    # Season\n",
    "\n",
    "    final_df_test['month'] = pd.DatetimeIndex(final_df_test['date_recorded']).month\n",
    "\n",
    "    # season encoder based on reports by water aid tanzania and https://tanzania-specialist.com/best-time-to-visit-tanzania/\n",
    "    season_mapper = {1: 'short dry', 2: 'short dry', 3: 'long rain', 4: 'long rain', 5: 'long rain', 6: 'long dry',\n",
    "                     7: 'long dry', 8: 'long dry', 9: 'long dry', 10: 'long dry', 11: 'short rain', 12: 'short rain'}\n",
    "    # .p feature values to scale\n",
    "    final_df_test['season'] = final_df_test['month'].replace(season_mapper)\n",
    "    final_df_test = final_df_test.drop('month', axis=1)\n",
    "\n",
    "    # Amount tsh missing\n",
    "\n",
    "    # where amount tsh isn't missing, the percentage of functional pumps is a lot higher\n",
    "    final_df_test['amount_tsh_missing'] = np.where(final_df_test['amount_tsh'].isna(), 1, 0)\n",
    "\n",
    "    # Region District\n",
    "    final_df_test['region_district'] = final_df_test['region'] + \"-\" + final_df_test['district_code']\n",
    "\n",
    "    # two decimal places is 1.1 km accurate. This will provide enough information on the location. Using the full coordinate doesn't provide a lot of general information, but does result in high cardinality\n",
    "    final_df_test['longitude'] = round(final_df_test['longitude'], 2)\n",
    "    final_df_test['latitude'] = round(final_df_test['latitude'], 2)\n",
    "\n",
    "    # i want to keep extraction type class and I will group the extraction type group en type together\n",
    "\n",
    "    # swn 80 and swn 81 become swn\n",
    "    # cemo + climax become other motorpump\n",
    "    # other -mkulima, other -play and walimi become other handpump\n",
    "\n",
    "    swn = ['other - swn 81', 'swn80']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(swn), 'swn',\n",
    "                                                final_df_test['extraction_type'])\n",
    "\n",
    "    other_handpump = ['other - mkulima/shinyanga', 'other - play pump', 'other - walimi']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(other_handpump), 'other handpump',\n",
    "                                                final_df_test['extraction_type'])\n",
    "\n",
    "    other_motorpump = ['cemo', 'climax']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(other_motorpump),\n",
    "                                                'other motorpump', final_df_test['extraction_type'])\n",
    "\n",
    "    # based on reports by water aid\n",
    "    # non autonomous = government, VWC, town council ..... also water authority, parastatal (=state company) SWC\n",
    "    # autonomous = WUA, WUG, board, trust, school\n",
    "    # private = private, company\n",
    "\n",
    "    non = ['VWC', 'Water authority', 'Parastatal', 'SWC']\n",
    "    autonomous = ['WUG', 'WUA', 'Water Board', 'Trust']\n",
    "    private = ['Company', 'Private operator']\n",
    "    other = ['None', 'Other']\n",
    "\n",
    "    final_df_test['authority_scheme'] = final_df_test['scheme_management']\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(non), 'authority_scheme'] = 'non-autonomous'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(autonomous), 'authority_scheme'] = 'autonomous'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(private), 'authority_scheme'] = 'private'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(other), 'authority_scheme'] = 'other'\n",
    "\n",
    "    # keep source, but the rare classes will be put together\n",
    "    other = ['other', 'unknown']\n",
    "    final_df_test['source'] = np.where(final_df_test['source'] == 'unknown', 'other', final_df_test['source'])\n",
    "\n",
    "    # Drop during EDA I already decided what features to keep and which ones to drop\n",
    "    final_df_test = final_df_test.drop(\n",
    "        ['Unnamed: 0', 'id', 'amount_tsh', 'date_recorded', 'wpt_name', 'num_private', 'subvillage', 'region',\n",
    "         'district_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'management',\n",
    "         'management_group', 'payment', 'quality_group', 'quantity_group', 'source_class', 'source_type',\n",
    "         'waterpoint_type_group', 'construction_year'], axis=1)\n",
    "    \n",
    "    # PREDICTION\n",
    "    # loading saved model\n",
    "    clf = load('clf.joblib')\n",
    "\n",
    "    # predict\n",
    "    test_pred = clf.predict(final_df_test)\n",
    "\n",
    "    # converting pretiction from numerical to actual srting values\n",
    "\n",
    "    if test_pred == 0:\n",
    "        return \"Pump is Functional\"\n",
    "    if test_pred == 2:\n",
    "        return\"Pump is Non Function\"\n",
    "    if test_pred == 1:\n",
    "        return\"Pump is functional but needs repair\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663b9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pump is Non Function\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "x = test.iloc[[0]]\n",
    "\n",
    "print(Function_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebe90a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pump is Non Function\n",
      "--- 2.282198905944824 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# Time taken to perdicting all test data\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "print(Function_1(x))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44bacfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Function_2(X,Y):\n",
    "\n",
    "    \"\"\" THIS FUNCTION TAKES RAW DATA AND DOSE PREPROCESSING AND FEATURE ENGG. AND predict using best model\"\"\"\n",
    "    test = X.copy()\n",
    "    # longitude\n",
    "    means_longitude_subvillage = pd.read_csv('means_longitude_subvillage.csv')\n",
    "    means_longitude_ward = pd.read_csv('means_longitude_ward.csv', )\n",
    "    means_longitude_lga = pd.read_csv('means_longitude_lga.csv', )\n",
    "    means_longitude_region = pd.read_csv('means_longitude_region.csv', )\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df this will make it easier to replace missing values\n",
    "    test = test.merge(means_longitude_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_longitude_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_longitude_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_longitude_region, how='left', on=['region'])\n",
    "\n",
    "    # select the right longitude level based on the availability of information\n",
    "    test['imputed_longitude'] = np.where(test['longitude'].isna(), test['longitude_imputed_subvillage'], test[\n",
    "        'longitude'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_ward'], test[\n",
    "        'imputed_longitude'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_lga'],\n",
    "                                         test['imputed_longitude'])\n",
    "    test['imputed_longitude'] = np.where(test['imputed_longitude'].isna(), test['longitude_imputed_region'],\n",
    "                                         test['imputed_longitude'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(\n",
    "        ['longitude_imputed_subvillage', 'longitude_imputed_ward', 'longitude_imputed_lga', 'longitude_imputed_region',\n",
    "         'longitude'], axis=1)\n",
    "\n",
    "    # Premit\n",
    "    permit_mg_mode = pd.read_csv('permit_mg_mode3.csv')\n",
    "\n",
    "    permit_mg_mode = permit_mg_mode.rename(columns={\"permit\": \"imputed_permit_mg\"})\n",
    "    test = test.merge(permit_mg_mode, how='left', on=['public_meeting', 'management_group'])\n",
    "\n",
    "    test['imputed_permit'] = np.where(test['permit'].isna(), test['imputed_permit_mg'], test[\n",
    "        'permit'])  # if permit is missing, replace it by the mode of public meeting - management group\n",
    "    test['imputed_permit'] = np.where(test['imputed_permit'].isna(), test['permit'].mode(), test[\n",
    "        'imputed_permit'])  # if eitther public meeting or management group is missing, then use the mode of permit (True)\n",
    "\n",
    "    # drop original permit column\n",
    "    test = test.drop(['permit', 'imputed_permit_mg'], axis=1)\n",
    "\n",
    "    #  Public Meeting\n",
    "    # True is  mode of public meeting.\n",
    "    # Over 90% of the pumps have a public meeting. I will therefore impute by the mode.\n",
    "    test['public_meeting'] = test['public_meeting'].fillna(True)\n",
    "\n",
    "    # Scheme management\n",
    "    scheme_mode = pd.read_csv('permit_mg_mode.csv')\n",
    "\n",
    "    # merge scheme_mode to original df and use it to replace missing values\n",
    "    test = test.merge(scheme_mode, how='left', on=['management'])\n",
    "    test['imputed_scheme__management'] = np.where(test['scheme_management'].isna(), test['imputed_scheme_management'],\n",
    "                                                  test['scheme_management'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['scheme_management', 'imputed_scheme_management'], axis=1)\n",
    "\n",
    "    # Installer\n",
    "    test['installer'] = test['installer'].str.lower()\n",
    "\n",
    "    # plot top 10 installers\n",
    "    test['installer'] = np.where(test['installer'] == 'gove', 'gover', test['installer'])\n",
    "    test['installer'] = np.where(test['installer'] == 'community', 'commu', test['installer'])\n",
    "    test['installer'] = np.where(test['installer'] == 'danid', 'danida', test['installer'])\n",
    "\n",
    "    inst150 = pd.read_csv('inst150.csv')\n",
    "    top_installers = np.array(inst150['0'])\n",
    "    # replace funders that are not in top 10 with 'other'\n",
    "    test['installer'] = np.where(test['installer'].isin(top_installers), test['installer'], 'other')\n",
    "\n",
    "    # Funder\n",
    "    # set al entries to lowercase\n",
    "    test['funder'] = test['funder'].str.lower()\n",
    "\n",
    "    fund150 = pd.read_csv('fundt150.csv')\n",
    "    top_funders = np.array(fund150['0'])\n",
    "\n",
    "    # replace funders that are not in top 150 with 'other'\n",
    "    test['funder'] = np.where(test['funder'].isin(top_funders), test['funder'], 'other')\n",
    "\n",
    "    # Construction Year\n",
    "    mean_construction = pd.read_csv('mean_construction.csv')\n",
    "\n",
    "    mean_construction = mean_construction.rename(columns={\"construction_year\": \"imputed_construction_year\"})\n",
    "\n",
    "    # merge this df to the main df and replace missing values\n",
    "    test = test.merge(mean_construction, how='left', on='extraction_type_group')\n",
    "    test['construction_year_imputed'] = np.where(test['construction_year'].isna(), test['imputed_construction_year'],\n",
    "                                                 test['construction_year'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['imputed_construction_year', 'construction_year'], axis=1)\n",
    "\n",
    "    # GPS height\n",
    "    # subvillage\n",
    "    means_altitude_subvillage = pd.read_csv('means_altitude_subvillage.csv', )\n",
    "\n",
    "    # ward level\n",
    "    means_altitude_ward = pd.read_csv('means_altitude_ward.csv')\n",
    "\n",
    "    # lga level\n",
    "    means_altitude_lga = pd.read_csv('means_altitude_lga.csv')\n",
    "\n",
    "    # region level\n",
    "    means_altitude_region = pd.read_csv('means_altitude_region.csv')\n",
    "\n",
    "    # region basin\n",
    "    means_altitude_basin = pd.read_csv('means_altitude_basin.csv')\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df\n",
    "    test = test.merge(means_altitude_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_altitude_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_altitude_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_altitude_region, how='left', on=['region'])\n",
    "    test = test.merge(means_altitude_basin, how='left', on=['basin'])\n",
    "\n",
    "    # create final imputed longitude column\n",
    "    test['imputed_gps_height'] = np.where(test['gps_height'].isna(), test['gps_height_imputed_subvillage'], test[\n",
    "        'gps_height'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_ward'], test[\n",
    "        'imputed_gps_height'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_lga'],\n",
    "                                          test['imputed_gps_height'])\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_region'],\n",
    "                                          test['imputed_gps_height'])\n",
    "    test['imputed_gps_height'] = np.where(test['imputed_gps_height'].isna(), test['gps_height_imputed_basin'],\n",
    "                                          test['imputed_gps_height'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['gps_height_imputed_subvillage', 'gps_height_imputed_ward', 'gps_height_imputed_lga',\n",
    "                      'gps_height_imputed_region', 'gps_height', 'gps_height_imputed_basin'], axis=1)\n",
    "\n",
    "    # Population\n",
    "\n",
    "    # subvillage\n",
    "    means_population_subvillage = pd.read_csv('means_population_subvillage.csv')\n",
    "\n",
    "    # ward level\n",
    "    means_population_ward = pd.read_csv('means_population_ward.csv')\n",
    "\n",
    "    # lga level\n",
    "    means_population_lga = pd.read_csv('means_population_lga.csv')\n",
    "\n",
    "    # region level\n",
    "    means_population_region = pd.read_csv('means_population_region.csv')\n",
    "\n",
    "    # region basin\n",
    "    means_population_basin = pd.read_csv('means_population_basin.csv')\n",
    "\n",
    "    # merge the aggregated dataframes as new columns to the original df\n",
    "    test = test.merge(means_population_subvillage, how='left', on=['region', 'lga', 'ward', 'subvillage'])\n",
    "    test = test.merge(means_population_ward, how='left', on=['region', 'lga', 'ward'])\n",
    "    test = test.merge(means_population_lga, how='left', on=['region', 'lga'])\n",
    "    test = test.merge(means_population_region, how='left', on=['region'])\n",
    "    test = test.merge(means_population_basin, how='left', on=['basin'])\n",
    "\n",
    "    # create final imputed longitude column\n",
    "    test['imputed_population'] = np.where(test['population'].isna(), test['population_imputed_subvillage'], test[\n",
    "        'population'])  # if longitude is missing, impute it by the mean of the subvillage\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_ward'], test[\n",
    "        'imputed_population'])  # if subvillage mean is missing, impute it by the ward\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_lga'],\n",
    "                                          test['imputed_population'])\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_region'],\n",
    "                                          test['imputed_population'])\n",
    "    test['imputed_population'] = np.where(test['imputed_population'].isna(), test['population_imputed_basin'],\n",
    "                                          test['imputed_population'])\n",
    "\n",
    "    # drop redundant columns\n",
    "    test = test.drop(['population_imputed_subvillage', 'population_imputed_ward', 'population_imputed_lga',\n",
    "                      'population_imputed_region', 'population', 'population_imputed_basin'], axis=1)\n",
    "\n",
    "    # change type to categorical\n",
    "\n",
    "    test['num_private'] = test['num_private'].astype('str')\n",
    "    test['region_code'] = test['region_code'].astype('str')\n",
    "    test['district_code'] = test['district_code'].astype('str')\n",
    "    test['num_private'] = test['num_private'].astype('str')\n",
    "\n",
    "    # replace string to integer\n",
    "    test['public_meeting'] = test['public_meeting'].replace({True: 1, False: 0})\n",
    "    test['imputed_permit'] = test['imputed_permit'].replace({True: 1, False: 0})\n",
    "\n",
    "    # change to integer\n",
    "    test[['imputed_gps_height', 'construction_year_imputed', 'imputed_population']] = test[\n",
    "        ['imputed_gps_height', 'construction_year_imputed', 'imputed_population']].astype('int')\n",
    "\n",
    "    # change type to categorical\n",
    "\n",
    "    # remove decimal\n",
    "    test['district_code'] = test['district_code'].str.split(\".\").str[0]\n",
    "\n",
    "    test = test.rename(columns={\"imputed_permit\": \"permit\", \"imputed_scheme__management\": \"scheme_management\",\n",
    "                                \"imputed_gps_height\": \"gps_height\", 'construction_year_imputed': 'construction_year',\n",
    "                                'imputed_population': 'population', 'imputed_longitude': 'longitude'}, errors=\"raise\")\n",
    "\n",
    "    final_df_test = test.copy()\n",
    "\n",
    "    # create age feature\n",
    "    final_df_test['recorded_year'] = pd.DatetimeIndex(final_df_test['date_recorded']).year\n",
    "    final_df_test['age'] = final_df_test['recorded_year'] - final_df_test['construction_year']\n",
    "    final_df_test = final_df_test.drop('recorded_year', axis=1)\n",
    "\n",
    "    # Season\n",
    "\n",
    "    final_df_test['month'] = pd.DatetimeIndex(final_df_test['date_recorded']).month\n",
    "\n",
    "    # season encoder based on reports by water aid tanzania and https://tanzania-specialist.com/best-time-to-visit-tanzania/\n",
    "    season_mapper = {1: 'short dry', 2: 'short dry', 3: 'long rain', 4: 'long rain', 5: 'long rain', 6: 'long dry',\n",
    "                     7: 'long dry', 8: 'long dry', 9: 'long dry', 10: 'long dry', 11: 'short rain', 12: 'short rain'}\n",
    "    # .p feature values to scale\n",
    "    final_df_test['season'] = final_df_test['month'].replace(season_mapper)\n",
    "    final_df_test = final_df_test.drop('month', axis=1)\n",
    "\n",
    "    # Amount tsh missing\n",
    "\n",
    "    # where amount tsh isn't missing, the percentage of functional pumps is a lot higher\n",
    "    final_df_test['amount_tsh_missing'] = np.where(final_df_test['amount_tsh'].isna(), 1, 0)\n",
    "\n",
    "    # Region District\n",
    "    final_df_test['region_district'] = final_df_test['region'] + \"-\" + final_df_test['district_code']\n",
    "\n",
    "    # two decimal places is 1.1 km accurate. This will provide enough information on the location. Using the full coordinate doesn't provide a lot of general information, but does result in high cardinality\n",
    "    final_df_test['longitude'] = round(final_df_test['longitude'], 2)\n",
    "    final_df_test['latitude'] = round(final_df_test['latitude'], 2)\n",
    "\n",
    "    # i want to keep extraction type class and I will group the extraction type group en type together\n",
    "\n",
    "    # swn 80 and swn 81 become swn\n",
    "    # cemo + climax become other motorpump\n",
    "    # other -mkulima, other -play and walimi become other handpump\n",
    "\n",
    "    swn = ['other - swn 81', 'swn80']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(swn), 'swn',\n",
    "                                                final_df_test['extraction_type'])\n",
    "\n",
    "    other_handpump = ['other - mkulima/shinyanga', 'other - play pump', 'other - walimi']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(other_handpump), 'other handpump',\n",
    "                                                final_df_test['extraction_type'])\n",
    "\n",
    "    other_motorpump = ['cemo', 'climax']\n",
    "    final_df_test['extraction_type'] = np.where(final_df_test['extraction_type'].isin(other_motorpump),\n",
    "                                                'other motorpump', final_df_test['extraction_type'])\n",
    "\n",
    "    # based on reports by water aid\n",
    "    # non autonomous = government, VWC, town council ..... also water authority, parastatal (=state company) SWC\n",
    "    # autonomous = WUA, WUG, board, trust, school\n",
    "    # private = private, company\n",
    "\n",
    "    non = ['VWC', 'Water authority', 'Parastatal', 'SWC']\n",
    "    autonomous = ['WUG', 'WUA', 'Water Board', 'Trust']\n",
    "    private = ['Company', 'Private operator']\n",
    "    other = ['None', 'Other']\n",
    "\n",
    "    final_df_test['authority_scheme'] = final_df_test['scheme_management']\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(non), 'authority_scheme'] = 'non-autonomous'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(autonomous), 'authority_scheme'] = 'autonomous'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(private), 'authority_scheme'] = 'private'\n",
    "    final_df_test.loc[final_df_test['authority_scheme'].isin(other), 'authority_scheme'] = 'other'\n",
    "\n",
    "    # keep source, but the rare classes will be put together\n",
    "    other = ['other', 'unknown']\n",
    "    final_df_test['source'] = np.where(final_df_test['source'] == 'unknown', 'other', final_df_test['source'])\n",
    "\n",
    "    # Drop during EDA I already decided what features to keep and which ones to drop\n",
    "    final_df_test = final_df_test.drop(\n",
    "        ['Unnamed: 0', 'id', 'amount_tsh', 'date_recorded', 'wpt_name', 'num_private', 'subvillage', 'region',\n",
    "         'district_code', 'lga', 'ward', 'recorded_by', 'scheme_name', 'extraction_type_group', 'management',\n",
    "         'management_group', 'payment', 'quality_group', 'quantity_group', 'source_class', 'source_type',\n",
    "         'waterpoint_type_group', 'construction_year'], axis=1)\n",
    "    # PREDICTION\n",
    "\n",
    "    #loading saved model\n",
    "    clf = load('clf.joblib') \n",
    "\n",
    "    #predict \n",
    "    test_pred = clf.predict(final_df_test)\n",
    "\n",
    "    micro_f1_score = f1_score(test_pred, Y, average='micro')\n",
    "\n",
    "    return micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69cfc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score 0.8056116722783389%\n"
     ]
    }
   ],
   "source": [
    "#Micro F1_score \n",
    "print(f'Micro F1 Score {Function_2(x_test,y_test)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
